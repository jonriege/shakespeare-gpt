{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ad129c4-2555-43ef-bb7d-e662a3b21ac7",
   "metadata": {},
   "source": [
    "# Train Transformer Decoder\n",
    "This notebook trains the Transformer Decoder that will be used to generate text and embeds it in a GPT class. It is based on the [Neural Machine Translation with a Transformer and Keras](https://www.tensorflow.org/text/tutorials/transformer) tutorial by TensorFlow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ff7984-9b6a-4d5c-be29-d3a1d98b6a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c8cbed-61e2-47f1-875d-4297c70f652d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow_text as text\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb18a7ef-a158-409d-b7f5-82dd7451bbea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c2bd93f-5b72-47e9-9778-61810dfa34ce",
   "metadata": {},
   "source": [
    "## Dataset and tokenizer\n",
    "Load dataset and tokenizer, see the tokenization notebook for details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe6dcb9-b37f-43d7-98c9-70450353e81a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.load(config.TRAIN_DATA_PATH)\n",
    "val_dataset = tf.data.Dataset.load(config.VAL_DATA_PATH)\n",
    "tokenizer = tf.saved_model.load(config.TOKENIZER_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd8b7e1-a32d-48c1-a706-2faa1635cc9b",
   "metadata": {},
   "source": [
    "## Make batches\n",
    "Split the tokenized dataset into input and target sequences, split into batches for model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "886d7564-07ad-4441-a4e8-3cc31a7fce80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_input_target(sequence):\n",
    "    input_text = sequence[:-1]\n",
    "    target_text = sequence[1:]\n",
    "    return input_text, target_text\n",
    "\n",
    "\n",
    "def make_batches(ds):\n",
    "    return (\n",
    "        ds.map(split_input_target, tf.data.AUTOTUNE)\n",
    "        .batch(config.BATCH_SIZE)\n",
    "        .prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39bd2f65-7013-477a-91cd-ea8208d5e14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batches = make_batches(train_dataset)\n",
    "val_batches = make_batches(val_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d45e19e-18fd-4648-a7b7-5ecea856c5f6",
   "metadata": {},
   "source": [
    "## Decoder\n",
    "Compile and train the Transformer Decoder model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2effac-97b6-4ced-9523-dbb0a28fb558",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import Decoder, masked_loss, masked_accuracy, CustomSchedule\n",
    "\n",
    "decoder = Decoder(\n",
    "    num_layers=config.N_LAYERS,\n",
    "    d_model=config.D_MODEL,\n",
    "    num_heads=config.N_HEADS,\n",
    "    dff=config.FFN_DIM,\n",
    "    vocab_size=config.VOCAB_SIZE,\n",
    "    dropout_rate=config.DROPOUT_RATE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e6b12e-965e-478a-a599-ceb529257dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the transformer by applying it to a sample\n",
    "for input_text, target_text in train_batches.take(1):\n",
    "    break\n",
    "decoder(input_text)\n",
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b173f19b-fea4-49f0-9a8a-e1903ffe1b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import CustomSchedule\n",
    "\n",
    "learning_rate = CustomSchedule(config.D_MODEL)\n",
    "optimizer = tf.keras.optimizers.legacy.Adam(\n",
    "    learning_rate=learning_rate, **config.OPTIMIZER_KWARGS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0597caf0-6ff3-4f81-b42c-8ee7cbe72dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(learning_rate(tf.range(40000, dtype=tf.float32)))\n",
    "plt.ylabel(\"Learning Rate\")\n",
    "plt.xlabel(\"Train Step\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de8ecc35-a94e-477e-b8be-28186cce6353",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import masked_loss, masked_accuracy\n",
    "\n",
    "decoder.compile(\n",
    "    loss=masked_loss, optimizer=optimizer, metrics=[masked_accuracy]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "978477fb-1763-47cc-9037-1cad46f2d877",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder.fit(\n",
    "    train_batches, epochs=config.N_EPOCHS, validation_data=val_batches\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50ccd2ce-5268-4013-9c0b-5f5980a308a8",
   "metadata": {},
   "source": [
    "## GPT\n",
    "Use the Decoder model and tokenizer in a GPT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be72935a-73f2-4c91-bfb8-f2d0fac56040",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_length = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "297d9ac4-7f67-40ec-8483-edc99a6e90a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "input = \"king lear:\"\n",
    "tokens = tokenizer.tokenize([input]).to_tensor()\n",
    "output_array = tf.TensorArray(dtype=tf.int64, size=0, dynamic_size=True)\n",
    "output_array = output_array.unstack(tokens[0])\n",
    "\n",
    "i = tokens.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0373f111-e4a6-4c3e-976c-cb5f392eabc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c3a108-b15e-4631-bdae-d9411438ce4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(output_length):\n",
    "    output_tensor = tf.expand_dims(output_array.stack(), axis=0)\n",
    "    \n",
    "    # Select the last predicted token from the `seq_len` dimension.\n",
    "    predictions = decoder(output_tensor, training=False)[:, -1:, :]  # Shape `(batch_size, 1, vocab_size)`.\n",
    "    predicted_token = tf.argmax(predictions, axis=-1)[0, 0]\n",
    "    output_array = output_array.write(i, predicted_token)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a2c5b7-ef97-4acd-a24f-04d54d9db8b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_tokens = tf.expand_dims(output_array.stack(), axis=0)\n",
    "generated_text = tokenizer.detokenize(predicted_tokens).numpy()[0].decode(\"utf-8\")\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ade7118-d3c0-4367-b398-a187b73c5bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"king lear : what , are you mad ? fool : no , no , no ; i ' ll be sworn . fool : why , i ' ll be sworn , sir , i ' ll be sworn . fool : why , i ' ll be sworn i am a fool . fool : why , then , nuncle , i ' ll be sworn i am a fool . fool : why , then , nuncle , i ' ll be sworn i ' ll be sworn i am a fool . fool : why , fool , i\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dcd3237-1daf-48b4-8ce9-f9b23e883f77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14878d8a-a649-4e19-a9a9-0ea89afa774b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPT(tf.Module):\n",
    "    \"\"\"\"\"\"\n",
    "\n",
    "    def __init__(self, tokenizer, decoder: tf.keras.Model, output_length: int):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.decoder = decoder\n",
    "        self.output_length = output_length\n",
    "\n",
    "    @tf.function\n",
    "    def __call__(self, prompt: str) -> str:\n",
    "        \"\"\"\"\"\"\n",
    "        tokens = self.tokenizer.tokenize([prompt]).to_tensor()\n",
    "        output_array = tf.TensorArray(dtype=tf.int64, size=0, dynamic_size=True)\n",
    "        output_array = output_array.unstack(tokens[0])\n",
    "        i = tf.shape(tokens)[1]\n",
    "        \n",
    "        for _ in range(self.output_length):\n",
    "            output_tensor = tf.expand_dims(output_array.stack(), axis=0)\n",
    "            \n",
    "            # Select the last predicted token from the `seq_len` dimension.\n",
    "            predictions = self.decoder(output_tensor, training=False)[:, -1:, :]  # Shape `(batch_size, 1, vocab_size)`.\n",
    "            predicted_token = tf.argmax(predictions, axis=-1)[0, 0]\n",
    "            output_array = output_array.write(i, predicted_token)\n",
    "            i += 1\n",
    "\n",
    "        predicted_tokens = tf.expand_dims(output_array.stack(), axis=0)\n",
    "        generated_text = self.tokenizer.detokenize(predicted_tokens)\n",
    "        return generated_text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a08c3c-93d6-4f31-823d-bfac45f49f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.saved_model.save(gpt, export_dir=config.GPT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6915ddef-ddd7-416b-93fa-b30da5b89f27",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
